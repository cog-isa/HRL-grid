{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "# from utils import plotting\n",
    "from arm_env_dqn import ArmEnvDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arm_model(img_in, num_actions, scope, reuse=False):\n",
    "    # as described in https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        out = img_in\n",
    "        with tf.variable_scope(\"convnet\"):\n",
    "            # original architecture\n",
    "            out = layers.convolution2d(out, num_outputs=32, kernel_size=8, stride=4, activation_fn=tf.nn.relu)\n",
    "            out = layers.convolution2d(out, num_outputs=64, kernel_size=4, stride=2, activation_fn=tf.nn.relu)\n",
    "            out = layers.convolution2d(out, num_outputs=64, kernel_size=3, stride=1, activation_fn=tf.nn.relu)\n",
    "        out = layers.flatten(out)\n",
    "        with tf.variable_scope(\"action_value\"):\n",
    "            out = layers.fully_connected(out, num_outputs=256,         activation_fn=tf.nn.relu)\n",
    "            out = layers.fully_connected(out, num_outputs=num_actions, activation_fn=None)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from dqn_graph1/dqn_graph.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 17:22:26,769] Restoring parameters from dqn_graph1/dqn_graph.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from dqn_graph2/dqn_graph.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-08 17:22:27,079] Restoring parameters from dqn_graph2/dqn_graph.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[3 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]]\n",
      "3 4\n",
      "\n",
      "[[0 0 0]\n",
      " [3 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]]\n",
      "4 4\n",
      "\n",
      "[[0 0 0]\n",
      " [2 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]]\n",
      "3 3\n",
      "\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [2 0 0]\n",
      " [1 1 1]]\n",
      "1 1\n",
      "\n",
      "[[0 0 0]\n",
      " [2 0 0]\n",
      " [1 0 0]\n",
      " [0 1 1]]\n",
      "2 2\n",
      "\n",
      "[[0 0 0]\n",
      " [0 2 0]\n",
      " [0 1 0]\n",
      " [0 1 1]]\n",
      "5 2\n",
      "\n",
      "[[0 0 0]\n",
      " [0 3 0]\n",
      " [0 1 0]\n",
      " [0 1 1]]\n",
      "2 4\n",
      "\n",
      "[[0 0 0]\n",
      " [0 0 3]\n",
      " [0 1 0]\n",
      " [0 1 1]]\n",
      "3 0\n",
      "\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 1 3]\n",
      " [0 1 1]]\n",
      "4 5\n",
      "\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 1 2]\n",
      " [0 1 1]]\n",
      "1 5\n",
      "\n",
      "[[0 0 0]\n",
      " [0 0 2]\n",
      " [0 1 1]\n",
      " [0 1 0]]\n",
      "1 1\n",
      "\n",
      "[[0 0 2]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n",
      "0 0\n",
      "\n",
      "[[0 2 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n",
      "5 2\n",
      "\n",
      "[[0 3 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n",
      "187 13\n"
     ]
    }
   ],
   "source": [
    "def encode_observation(frame):\n",
    "    img_h, img_w = frame.shape[1], frame.shape[2]\n",
    "    return frame.transpose(1, 2, 0, 3).reshape(img_h, img_w, -1)\n",
    "\n",
    "def main():\n",
    "    env = ArmEnvDQN(episode_max_length=200,\n",
    "                 size_x=4,\n",
    "                 size_y=3,\n",
    "                 cubes_cnt=3,\n",
    "                 scaling_coeff=3,\n",
    "                 action_minus_reward=-1,\n",
    "                 finish_reward=200,\n",
    "                 tower_target_size=3)\n",
    "    \n",
    "    g1 = tf.Graph()\n",
    "    g2 = tf.Graph()\n",
    "    \n",
    "    sess1 = tf.Session(graph=g1)\n",
    "\n",
    "    with g1.as_default():\n",
    "        saver1 = tf.train.import_meta_graph('dqn_graph1/dqn_graph.ckpt.meta', import_scope = 'option1')\n",
    "        saver1.restore(sess1, \"dqn_graph1/dqn_graph.ckpt\")\n",
    "        \n",
    "    sess2 = tf.Session(graph=g2)\n",
    "    \n",
    "    with g2.as_default():\n",
    "        saver2 = tf.train.import_meta_graph('dqn_graph2/dqn_graph.ckpt.meta', import_scope = 'option2')\n",
    "        saver2.restore(sess2, \"dqn_graph2/dqn_graph.ckpt\")\n",
    "    \n",
    "#     saver.restore(session, tf.train.latest_checkpoint('./'))\n",
    "#     self.frame_history_len = 1\n",
    "#     img_h, img_w, img_c = env.observation_space.shape\n",
    "#     input_shape = (img_h, img_w, frame_history_len * img_c)  # size_x, size_y,\n",
    "#     num_actions = env.action_space.n\n",
    "    \n",
    "    # print(env.reset())\n",
    "#     with tf.variable_scope('option2'):\n",
    "# #         with tf.variable_scope(\"obs_t_ph\"):\n",
    "#         # placeholder for current observation (or state)\n",
    "#         obs_t_ph = tf.placeholder(tf.uint8, [None] + list(input_shape), name = \"obs_t_ph\")\n",
    "#         # casting to float on GPU ensures lower data transfer times.\n",
    "#         obs_t_float = tf.realdiv(tf.cast(obs_t_ph, tf.float32), 255.0, name = 'obs_t_float')\n",
    "            \n",
    "#         pred_q = arm_model(obs_t_float, num_actions, scope=\"q_func\", reuse=False)\n",
    "#         pred_ac = tf.argmax(pred_q, axis=1, name = \"pred_ac\")\n",
    "        \n",
    "#     pred_q = arm_model(obs_t_float, num_actions, scope=\"q_func\", reuse=False)\n",
    "#     pred_ac = tf.argmax(pred_q, axis=1, name = \"pred_ac\")\n",
    "    \n",
    "    # First let's load meta graph and restore weights\n",
    "#     saver = tf.train.import_meta_graph('dqn_graph.ckpt.meta', import_scope = 'q_func', \n",
    "#                                        input_map = {'obs_t_ph/obs_t_float': obs_t_float})\n",
    "#     saver = tf.train.Saver()\n",
    "\n",
    "#      # placeholder for current observation (or state)\n",
    "#     obs_t_ph = tf.placeholder(tf.uint8, [None] + list(input_shape))\n",
    "#      # casting to float on GPU ensures lower data transfer times.\n",
    "#     obs_t_float = tf.cast(obs_t_ph, tf.float32) / 255.0\n",
    "\n",
    "\n",
    "\n",
    "#     pred_q = q_func(obs_t_float, num_actions, scope=\"q_func\", reuse=False)\n",
    "#     pred_ac = tf.argmax(pred_q, axis=1)\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    obs_t_float2 = g2.get_tensor_by_name(\"option2/obs_t_float:0\")\n",
    "    pred_ac2 = g2.get_tensor_by_name(\"option2/pred_ac:0\")\n",
    "    \n",
    "    \n",
    "    obs_t_float1 = g1.get_tensor_by_name(\"option1/obs_t_float:0\")\n",
    "    pred_ac1 = g1.get_tensor_by_name(\"option1/pred_ac:0\")\n",
    "    \n",
    "#     obs_t_float2 = graph.get_tensor_by_name(\"obs_t_ph_lift:0\")\n",
    " \n",
    "    ## How to access saved operation\n",
    "#     pred_ac2 = graph.get_tensor_by_name(\"pred_ac_lift:0\")\n",
    "    \n",
    "    episode_reward = 0\n",
    "    episode_length = 0\n",
    "    last_obs = env.reset()\n",
    "    \n",
    "#     session = tf.Session()\n",
    "\n",
    "#     sess1 = tf.Session(graph=g1)\n",
    "    \n",
    "#     saver2.restore(session, \"/tmp/option_lift_cube.ckpt\")\n",
    "#     saver.restore(session, \"dqn_graph2/dqn_graph.ckpt\")\n",
    "#     saver2.restore(session, \"dqn_graph1/dqn_graph.ckpt\")\n",
    "    \n",
    "    \n",
    "    for t in itertools.count():\n",
    "\n",
    "        env.render()\n",
    "        obs = encode_observation(np.array([last_obs]))\n",
    "        action = sess1.run(pred_ac1, {obs_t_float1: [obs]})[0]\n",
    "        \n",
    "        action2 = sess2.run(pred_ac2, {obs_t_float2: [obs]})[0]\n",
    "        print(action, action2)\n",
    "\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "\n",
    "        episode_reward += reward\n",
    "        episode_length += 1\n",
    "\n",
    "        if done or episode_length == 500:\n",
    "            env.render()\n",
    "            break\n",
    "\n",
    "        last_obs = next_obs\n",
    "    print(episode_reward, episode_length)\n",
    "    \n",
    "#     episode_reward = 0\n",
    "#     episode_length = 0\n",
    "#     last_obs = env.reset()\n",
    "    \n",
    "#     for t in itertools.count():\n",
    "\n",
    "#         env.render()\n",
    "#         obs = encode_observation(np.array([last_obs]))\n",
    "#         action = sess2.run(pred_ac2, {obs_t_float2: [obs]})[0]\n",
    "\n",
    "#         next_obs, reward, done, info = env.step(action)\n",
    "\n",
    "#         episode_reward += reward\n",
    "#         episode_length += 1\n",
    "\n",
    "#         if done or episode_length == 500:\n",
    "#             env.render()\n",
    "#             break\n",
    "\n",
    "#         last_obs = next_obs\n",
    "#     print(episode_reward, episode_length)\n",
    "    \n",
    "    tf.summary.FileWriter(\"logs_g1\", g1).close()\n",
    "    tf.summary.FileWriter(\"logs_g2\", g2).close()\n",
    "    \n",
    "#     episode_reward = 0\n",
    "#     episode_length = 0\n",
    "#     last_obs = env2.reset()\n",
    "#     for t in itertools.count():\n",
    "\n",
    "#         env2.render()\n",
    "#         obs = encode_observation(np.array([last_obs]))\n",
    "#         action = session.run(pred_ac2, {obs_t_float2: [obs]})[0]\n",
    "\n",
    "#         next_obs, reward, done, info = env2.step(action)\n",
    "\n",
    "#         episode_reward += reward\n",
    "#         episode_length += 1\n",
    "\n",
    "#         if done or episode_length == 500:\n",
    "#             env2.render()\n",
    "#             break\n",
    "\n",
    "#         last_obs = next_obs\n",
    "#     print(episode_reward, episode_length)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tensorboard --logdir=logs_g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
